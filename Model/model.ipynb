{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def einlesen(): \n",
    "\n",
    "    #FALLS\n",
    "    FOL=[]\n",
    "    FKL=[]\n",
    "    BSC=[]\n",
    "    SDL=[]\n",
    "    \n",
    "    #ADL\n",
    "    CHU=[]\n",
    "    SCH=[]\n",
    "    STU=[]\n",
    "    STN=[]\n",
    "    CSI=[]\n",
    "    CSO=[]\n",
    "    JOG=[]\n",
    "    JUM=[]\n",
    "    SIT=[]\n",
    "    STD=[]\n",
    "    WAL=[]\n",
    "\n",
    "    #Path to MobiAct_Dataset_v2\n",
    "    pfad=\"\\\\MobiAct_Dataset_v2\"\n",
    "    #FALLS\n",
    "   \n",
    "    #FOL    \n",
    "    FOL=[pd.read_csv(pfad+\"\\Annotated Data\\FOL\\FOL_{0}_{1}_annotated.csv\".format(i,a),usecols=[\"rel_time\",\"acc_x\",\"acc_y\",\"acc_z\",\"gyro_x\",\"gyro_y\",\"gyro_z\"])\n",
    "    for a in range(1,4)\n",
    "        for i in range(1,68)\n",
    "            if os.path.exists(pfad+\"\\Annotated Data\\FOL\\FOL_{0}_{1}_annotated.csv\".format(i,a))\n",
    "            ]\n",
    "    return FOL,FKL,BSC,SDL,CHU,SCH,STU,STN,CSI,CSO,JOG,JUM,SIT,STD,WAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 = fall 0 = ADL - Ad labels\n",
    "def label(data, is_fall):\n",
    "       # Falls (1)\n",
    "  if is_fall == 1:\n",
    "      for i in range(len(data)):\n",
    "          data[i][\"Label\"]=1  \n",
    "       #ADLs (0)        \n",
    "  else: \n",
    "      for i in range(len(data)):\n",
    "          data[i][\"Label\"]=0\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a data_vector\n",
    "def create_data_vector(list): \n",
    "    data_vector=[]\n",
    "    for item in list: \n",
    "        for i in range(len(item)): \n",
    "            data_vector.append(item[i])\n",
    "    \n",
    "    #Shuffle array\n",
    "    random.shuffle(data_vector)\n",
    "    return data_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Position: 0 1 DataFrames Label -- Matrix Create\n",
    "def create_data_matrix(data_vector):\n",
    "   data_matrix=([],[])\n",
    "   for i in range(len(data_vector)):\n",
    "       data_matrix[0].append(data_vector[i][[\"acc_x\",\"acc_y\",\"acc_z\",\"gyro_x\",\"gyro_y\",\"gyro_z\"]])\n",
    "       data_matrix[1].append(data_vector[i].at[0,\"Label\"]) # Only the label is taken out of the entire column\n",
    "       \n",
    "   return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_convert():\n",
    "   test=[],[]\n",
    "   train=[],[]\n",
    "   test = data_matrix[0][:400],data_matrix[1][:400] # Test and traindata split\n",
    "   train = data_matrix[0][400:],data_matrix[1][400:] \n",
    "   \n",
    "   print(\"Split Successful! Number of training data:{0} and test data:{1} \".format(len(train[0]),len(test[0]))) \n",
    "\n",
    "   train_data=[]\n",
    "   labels=[]\n",
    "   test_data=[]\n",
    "   test_labels=[]\n",
    "\n",
    "   for i in range(len(train[0])):\n",
    "       train_data.append(train[0][i].values)\n",
    "\n",
    "\n",
    "   for i in range(len(train[1])):\n",
    "       labels.append(train[1][i])\n",
    "   labels=np.array(labels)\n",
    "   for i in range(len(test[0])):\n",
    "       test_data.append(test[0][i].values) \n",
    "   for i in range(len(test[1])): \n",
    "       test_labels.append(test[1][i])\n",
    "   test_labels=np.array(test_labels)\n",
    "   return train_data,labels,test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the model\n",
    "def train_model(train_data,labels,test_data, test_labels):\n",
    "\n",
    "   model = keras.Sequential([     \n",
    "   keras.layers.Flatten(), \n",
    "   keras.layers.Masking(mask_value=0.0),\n",
    "   keras.layers.Dense(109, activation=tf.nn.softsign), \n",
    "   keras.layers.Dense(50, activation=tf.nn.softmax),\n",
    "   ]) \n",
    "   optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.003)\n",
    "   model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "   \n",
    "   #We had to bring every array to the same length\n",
    "   train_data=keras.preprocessing.sequence.pad_sequences(train_data, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
    "   train_data=np.array(train_data)\n",
    "   test_data=keras.preprocessing.sequence.pad_sequences(test_data, maxlen=train_data.shape[1], dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
    "   test_data=np.array(test_data) \n",
    "   history=model.fit(train_data,labels,validation_split=0.15,batch_size=100, epochs=5500 ) \n",
    "   \n",
    "   \n",
    "   model.summary()  \n",
    "   print(test_labels.shape,labels.shape)\n",
    "   print(test_data.shape,train_data.shape)\n",
    "   # Test Model\n",
    "   test_loss, test_acc = model.evaluate(test_data, test_labels) \n",
    "   print('Test accuracy:', test_acc) \n",
    "   print('Test loss:', test_loss)\n",
    "   model.save('simple_mlp5500.pb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available()) #GPU rendering speeds up the process\n",
    "FOL,FKL,BSC,SDL,CHU,SCH,STU,STN,CSI,CSO,JOG,JUM,SIT,STD,WAL=einlesen()\n",
    "#Label all the data\n",
    "\n",
    "FOL=label(FOL,1)   \n",
    "FKL=label(FKL,1)\n",
    "BSC=label(BSC,1)\n",
    "SDL=label(SDL,1)\n",
    "CHU=label(CHU,0)\n",
    "SCH=label(SCH,0)\n",
    "STU=label(STU,0)\n",
    "STN=label(STN,0)\n",
    "CSI=label(CSI,0)\n",
    "CSO=label(CSO,0)\n",
    "JOG=label(JOG,0)\n",
    "JUM=label(JUM,0)\n",
    "SIT=label(SIT,0)\n",
    "STD=label(STD,0)\n",
    "WAL=label(WAL,0)\n",
    "\n",
    "data_vector=create_data_vector([FOL,FKL,BSC,SDL,CHU,SCH,STU,STN,CSI,CSO,JOG,JUM,SIT,STD,WAL])\n",
    "data_matrix=create_data_matrix(data_vector)\n",
    "\n",
    "train_data, labels,test_data, test_labels=data_convert()\n",
    "train_model(train_data,labels, test_data, test_labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
